{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet.data_loader.read_file import read_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_task(\n",
    "    task: dict, \n",
    "    task_solutions: list, \n",
    "    idx: int, \n",
    "    key: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots the train and test pairs of a specified task,\n",
    "    using same color scheme as the ARC app.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    task\n",
    "        \"test\": [{\"input\": [], \"output\": []}]\n",
    "        \"train\": [{\"input\": [], \"output\": []}, ...]\n",
    "    task_solutions: List[List[int]]\n",
    "        n x n matrix\n",
    "    idx: int\n",
    "        index of the task\n",
    "    key: str\n",
    "        key of the task\n",
    "    \"\"\"\n",
    "    num_train = len(task['train'])\n",
    "    num_test  = len(task['test'])\n",
    "\n",
    "    w=num_train+num_test\n",
    "    fig, axs  = plt.subplots(2, w, figsize=(3*w ,3*2))\n",
    "    plt.suptitle(f'Set #{idx}, {key}:', fontsize=20, fontweight='bold', y=1)\n",
    "\n",
    "    for j in range(num_train):\n",
    "        plot_one(task, axs[0, j], j,'train', 'input')\n",
    "        plot_one(task, axs[1, j], j,'train', 'output')\n",
    "\n",
    "    plot_one(task, axs[0, j+1], 0, 'test', 'input')\n",
    "\n",
    "    cmap = colors.ListedColormap(['#000000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',\n",
    "                                  '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    answer = task_solutions\n",
    "    input_matrix = answer\n",
    "\n",
    "    axs[1, j+1].imshow(input_matrix, cmap=cmap, norm=norm)\n",
    "    axs[1, j+1].grid(True, which = 'both',color = 'lightgrey', linewidth = 0.5)\n",
    "    axs[1, j+1].set_yticks([x-0.5 for x in range(1 + len(input_matrix))])\n",
    "    axs[1, j+1].set_xticks([x-0.5 for x in range(1 + len(input_matrix[0]))])\n",
    "    axs[1, j+1].set_xticklabels([])\n",
    "    axs[1, j+1].set_yticklabels([])\n",
    "    axs[1, j+1].set_title('TEST OUTPUT', color = 'green', fontweight='bold')\n",
    "\n",
    "    fig.patch.set_linewidth(5)\n",
    "    fig.patch.set_edgecolor('black')  # substitute 'k' for black\n",
    "    fig.patch.set_facecolor('#dddddd')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "\n",
    "def plot_one(\n",
    "    task: dict, \n",
    "    ax, \n",
    "    i: int, \n",
    "    train_or_test: str, \n",
    "    input_or_output: str,\n",
    "):\n",
    "    cmap = colors.ListedColormap(['#000000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',\n",
    "                                  '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "    norm = colors.Normalize(vmin=0, vmax=9)\n",
    "    input_matrix = task[train_or_test][i][input_or_output]\n",
    "    ax.imshow(input_matrix, cmap=cmap, norm=norm)\n",
    "    ax.grid(True, which = 'both',color = 'lightgrey', linewidth = 0.5)\n",
    "\n",
    "    plt.setp(plt.gcf().get_axes(), xticklabels=[], yticklabels=[])\n",
    "    ax.set_xticks([x-0.5 for x in range(1 + len(input_matrix[0]))])\n",
    "    ax.set_yticks([x-0.5 for x in range(1 + len(input_matrix))])\n",
    "    ax.set_title(train_or_test + ' ' + input_or_output, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def pad_matrix(\n",
    "    matrix: List[List[int]], \n",
    "    target_shape=(30, 30), \n",
    "    pad_value=-1\n",
    "):\n",
    "    \"\"\"\n",
    "    Pad the input matrix to the target shape, placing the original values in the center.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : numpy.ndarray\n",
    "        The input matrix to be padded.\n",
    "    target_shape : tuple, optional\n",
    "        The desired shape of the output matrix. Default is (30, 30).\n",
    "    pad_value : int or float, optional\n",
    "        The value to use for padding. Default is -1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The padded matrix with the original values in the center.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> from your_module import pad_matrix\n",
    "    >>> input_matrix = np.array([[1, 2], [3, 4]])\n",
    "    >>> padded_matrix = pad_matrix(input_matrix)\n",
    "    >>> print(padded_matrix.shape)\n",
    "    (30, 30)\n",
    "    \"\"\"\n",
    "    matrix = np.array(matrix)\n",
    "    n, p = matrix.shape\n",
    "    target_n, target_p = target_shape\n",
    "\n",
    "    pad_n = (target_n - n) // 2\n",
    "    pad_p = (target_p - p) // 2\n",
    "\n",
    "    padded_matrix = np.full(target_shape, pad_value)\n",
    "    padded_matrix[pad_n:pad_n+n, pad_p:pad_p+p] = matrix\n",
    "\n",
    "    return padded_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = Path(\"./data\")\n",
    "ARC_PRICE_DATASET_PATH  = DATASET_PATH / \"arc-price-2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_training_challenges = \"arc-agi_training_challenges.json\"\n",
    "file_name_training_solutions = \"arc-agi_training_solutions.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_challenges = read_json(ARC_PRICE_DATASET_PATH / file_name_training_challenges)\n",
    "training_solutions = read_json(ARC_PRICE_DATASET_PATH / file_name_training_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "train_inputs = defaultdict(list)\n",
    "train_outputs = defaultdict(list)\n",
    "\n",
    "train_inputs_flatten = []\n",
    "train_outputs_flatten = []\n",
    "\n",
    "\"\"\"training_challenges structure\n",
    "{\n",
    "    task_name_1: {\n",
    "        \"train\": [\n",
    "            {\n",
    "                \"input\": input_matrix,\n",
    "                \"output\": output_matrix,\n",
    "            }\n",
    "        ]\n",
    "        \"test\": [\n",
    "            {\n",
    "                \"input\": input_matrix,\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    task_name_2: ...\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "for task_name in training_challenges:\n",
    "    task = training_challenges[task_name]\n",
    "    for train_observation in task[\"train\"]:\n",
    "        # by task\n",
    "        train_inputs[task_name].append(\n",
    "            pad_matrix(train_observation[\"input\"])  # to 30x30\n",
    "        )\n",
    "        train_outputs[task_name].append(\n",
    "            pad_matrix(train_observation[\"output\"])  # to 30x30\n",
    "        )\n",
    "\n",
    "        # flatten\n",
    "        train_inputs_flatten.append(\n",
    "            pad_matrix(train_observation[\"input\"])  # to 30x30\n",
    "        )\n",
    "        train_outputs_flatten.append(\n",
    "            pad_matrix(train_observation[\"output\"])  # to 30x30\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet.data_loader.data_loader import ImageDataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "batch_size = 4  # TODO: 추후 수정\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        ToTensor(),\n",
    "        Lambda(lambda x: x.float()),  # 명시적으로 float 타입으로 변환\n",
    "    ]\n",
    ")\n",
    "dataset_train = ImageDataset(\n",
    "    input_data=train_inputs_flatten,\n",
    "    output_data=train_outputs_flatten,\n",
    "    transform=transform,\n",
    ")\n",
    "loader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 30, 30])\n",
      "torch.Size([4, 1, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "for i, o in loader_train:\n",
    "    print(i.shape)\n",
    "    print(o.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet.unet import UNet\n",
    "from unet.train import Trainer\n",
    "\n",
    "model = UNet()\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=loader_train,\n",
    "    val_loader=loader_train,\n",
    "    save_path=\"model.pth\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 2 but got size 3 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/shared/youngjae/unet/unet/train.py:70\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m     67\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 70\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_epoch()\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mstep(val_loss)\n",
      "File \u001b[0;32m~/workspace/shared/youngjae/unet/unet/train.py:101\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), targets\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 101\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, targets)\n\u001b[1;32m    103\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/shared/youngjae/unet/unet/unet.py:208\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    205\u001b[0m dec5_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec5_1(enc5_1)\n\u001b[1;32m    207\u001b[0m unpool4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpool4(dec5_1)\n\u001b[0;32m--> 208\u001b[0m cat4 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43munpool4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc4_2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m dec4_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec4_2(cat4)\n\u001b[1;32m    210\u001b[0m dec4_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdec4_1(dec4_2)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 2 but got size 3 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "trainer.train(num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
